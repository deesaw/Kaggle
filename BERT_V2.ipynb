{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom bs4 import BeautifulSoup\nimport spacy\nimport re,string,unicodedata\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.stem import LancasterStemmer,WordNetLemmatizer\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom textblob import TextBlob\nfrom textblob import Word\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ktrain","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting ktrain\n  Downloading ktrain-0.25.0.tar.gz (25.3 MB)\n\u001b[K     |████████████████████████████████| 25.3 MB 23.9 MB/s eta 0:00:01   |▊                               | 552 kB 2.8 MB/s eta 0:00:09\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from ktrain) (0.23.2)\nRequirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from ktrain) (3.2.1)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.1.4)\nRequirement already satisfied: fastprogress>=0.1.21 in /opt/conda/lib/python3.7/site-packages (from ktrain) (1.0.0)\nCollecting keras_bert>=0.86.0\n  Downloading keras-bert-0.86.0.tar.gz (26 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ktrain) (2.23.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from ktrain) (0.14.1)\nCollecting langdetect\n  Downloading langdetect-1.0.8.tar.gz (981 kB)\n\u001b[K     |████████████████████████████████| 981 kB 43.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jieba in /opt/conda/lib/python3.7/site-packages (from ktrain) (0.42.1)\nCollecting cchardet\n  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n\u001b[K     |████████████████████████████████| 263 kB 51.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: networkx>=2.3 in /opt/conda/lib/python3.7/site-packages (from ktrain) (2.4)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.7/site-packages (from ktrain) (2.2.3)\nCollecting seqeval==0.0.19\n  Downloading seqeval-0.0.19.tar.gz (30 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ktrain) (20.1)\nRequirement already satisfied: transformers>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from ktrain) (3.4.0)\nRequirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from ktrain) (7.13.0)\nCollecting syntok\n  Downloading syntok-1.3.1.tar.gz (23 kB)\nCollecting whoosh\n  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n\u001b[K     |████████████████████████████████| 468 kB 53.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->ktrain) (1.4.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->ktrain) (1.18.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->ktrain) (2.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.1->ktrain) (2019.3)\nRequirement already satisfied: Keras>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from keras_bert>=0.86.0->ktrain) (2.4.3)\nCollecting keras-transformer>=0.38.0\n  Downloading keras-transformer-0.38.0.tar.gz (11 kB)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ktrain) (2020.11.8)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect->ktrain) (1.14.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.3->ktrain) (4.4.2)\nCollecting tornado>=5.1\n  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n\u001b[K     |████████████████████████████████| 428 kB 43.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh->ktrain) (5.3.1)\nRequirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.7/site-packages (from bokeh->ktrain) (8.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh->ktrain) (3.7.4.1)\nRequirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh->ktrain) (2.11.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (3.0.10)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (3.14.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (2020.4.4)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (0.1.94)\nRequirement already satisfied: tokenizers==0.9.2 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (0.9.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (4.45.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=3.1.0->ktrain) (0.0.43)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (4.8.0)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (0.1.0)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (2.6.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (3.0.5)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (46.1.3.post20200325)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (0.7.5)\nRequirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (0.15.2)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->ktrain) (4.3.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras>=2.4.3->keras_bert>=0.86.0->ktrain) (2.10.0)\nCollecting keras-pos-embd>=0.11.0\n  Downloading keras-pos-embd-0.11.0.tar.gz (5.9 kB)\nCollecting keras-multi-head>=0.27.0\n  Downloading keras-multi-head-0.27.0.tar.gz (14 kB)\nCollecting keras-layer-normalization>=0.14.0\n  Downloading keras-layer-normalization-0.14.0.tar.gz (4.3 kB)\nCollecting keras-position-wise-feed-forward>=0.6.0\n  Downloading keras-position-wise-feed-forward-0.6.0.tar.gz (4.4 kB)\nCollecting keras-embed-sim>=0.8.0\n  Downloading keras-embed-sim-0.8.0.tar.gz (4.1 kB)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=3.1.0->ktrain) (7.1.1)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.1.9)\nRequirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython->ktrain) (0.5.2)\nRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n","name":"stdout"},{"output_type":"stream","text":"Collecting keras-self-attention==0.46.0\n  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\nBuilding wheels for collected packages: ktrain, keras-bert, langdetect, seqeval, syntok, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n  Building wheel for ktrain (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.25.0-py3-none-any.whl size=25274500 sha256=f981d2cf776ae1777e26ee435aea21cdf22d8ee5644a8da7814bc2bebbf0ba96\n  Stored in directory: /root/.cache/pip/wheels/ef/4b/a8/7ef8b32fcba22ad93b43eefd341ba451f80d9ef1c24e5c6061\n  Building wheel for keras-bert (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-bert: filename=keras_bert-0.86.0-py3-none-any.whl size=34147 sha256=9c7d3a640d4a6f785d34277e85da22f8af887a3ce258bcbcf8f9e64b26d4ce1c\n  Stored in directory: /root/.cache/pip/wheels/fc/c1/0a/eb9187261b3f192ac314aefb54fe66f50540c3edb906599633\n  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=fc68863323803f55088786aac020c6ca055702204932f3a7b11a124a1146db1a\n  Stored in directory: /root/.cache/pip/wheels/59/f6/9d/85068904dba861c0b9af74e286265a08da438748ee5ae56067\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9917 sha256=f4b857d0a7e2ba1e5908cdffa15837b21829b7884635fa714b55ed563960b805\n  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n  Building wheel for syntok (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20916 sha256=b0edeec6e1ea0cd10d635392f7aa1bf253485b4539b88cd3b86150ac51d762a4\n  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n  Building wheel for keras-transformer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-py3-none-any.whl size=12941 sha256=ff279b238908d29250bf59c131263efb291cc2f69638b011dd288fd8296faa49\n  Stored in directory: /root/.cache/pip/wheels/b3/67/58/bcfb43b6ab764496a446021a8d05991adffd48c16582381326\n  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-py3-none-any.whl size=7553 sha256=5602ab9d9404972fbfbe9be581c219c093398d650f7c84602cd4b3fca2b09832\n  Stored in directory: /root/.cache/pip/wheels/65/66/e9/c7eafddc29b81a98786f12b48a2aee7e3c633f6bf4a62cbc20\n  Building wheel for keras-multi-head (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-py3-none-any.whl size=15613 sha256=751bce79953ac5a9be6062f5cac10b35f12d06be73c7e5b646e503b237b996fe\n  Stored in directory: /root/.cache/pip/wheels/21/38/cc/50e6d62d6d458e8223d3ddaef7c622b67ae57708193918051b\n  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-py3-none-any.whl size=5267 sha256=51729cf9efff5a43fecb3a0b4d8c0a5d732492bc4861dc0395fbd999d01232fe\n  Stored in directory: /root/.cache/pip/wheels/58/14/24/76b0d99b7d9cc17e110956e0fae825a5da3e70a60273220502\n  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-py3-none-any.whl size=5623 sha256=7983ed2a95613ee4410c266893471ed09a8f8d680f1a41eb31d86fd063527a2c\n  Stored in directory: /root/.cache/pip/wheels/9e/53/a2/651c985b605e6a6c48688c779808eb1956fabb910b0557d871\n  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-py3-none-any.whl size=4558 sha256=495ecadf162584a07a43d7d0cf23eb66ca3d30b54c034affeabba65bbdb9f433\n  Stored in directory: /root/.cache/pip/wheels/2d/31/2c/2d3fb4442f6112b92cd56bf801ff25421f302c755f935d4a79\n  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=b18c5cadc6f169a422428f5bdd0fd989812a136b388697febb874724946a1087\n  Stored in directory: /root/.cache/pip/wheels/ec/f7/48/30de93f8333298bad9202aab9b04db0cfd58dcd379b5a5ef1c\nSuccessfully built ktrain keras-bert langdetect seqeval syntok keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\nInstalling collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, syntok, whoosh, ktrain, tornado\n  Attempting uninstall: tornado\n    Found existing installation: tornado 5.0.2\n    Uninstalling tornado-5.0.2:\n      Successfully uninstalled tornado-5.0.2\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\njupyterlab-git 0.10.0 requires nbdime<2.0.0,>=1.1.0, but you'll have nbdime 2.0.0 which is incompatible.\ndask-xgboost 0.1.11 requires xgboost<=0.90, but you'll have xgboost 1.2.1 which is incompatible.\u001b[0m\nSuccessfully installed cchardet-2.1.7 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.25.0 langdetect-1.0.8 seqeval-0.0.19 syntok-1.3.1 tornado-6.1 whoosh-2.7.4\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport ktrain\nfrom ktrain import text\nimport tensorflow as tf","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'2.3.1'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/usi-nlp-practicum-2\"))\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":5,"outputs":[{"output_type":"stream","text":"['glove.6B.50d.txt', 'sample_submission.csv', 'imdb_train.csv', 'winequality-red.csv', 'imdb_test_data.csv', 'winequality-white.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the training data\ndata_train = pd.read_csv('../input/usi-nlp-practicum-2/imdb_train.csv')\nprint(data_train.shape)\nprint(data_train.head(10))\n#importing the training data\ndata_test=pd.read_csv('../input/usi-nlp-practicum-2/imdb_test_data.csv')\nprint(data_test.shape)\nprint(data_test.head(10))","execution_count":6,"outputs":[{"output_type":"stream","text":"(40000, 2)\n                                              review sentiment\n0  We had STARZ free weekend and I switched on th...  negative\n1  I'll admit that this isn't a great film. It pr...  negative\n2  I finally found a version of Persuasion that I...  positive\n3  The BBC surpassed themselves with the boundari...  positive\n4  Much praise has been lavished upon Farscape, b...  negative\n5  Of course the plot, script, and, especially ca...  positive\n6  This is one of those road movies that would li...  negative\n7  What an uninteresting hodge-podge. It could ha...  negative\n8  Only a handful of the segments are engaging he...  negative\n9  THE GREEN BUTCHERS (Anders Thomas Jensen - Den...  positive\n(10000, 2)\n   id                                             review\n0   1  Not only is this movie a great film for basic ...\n1   2  Waitress: Honey, here's them eggs you ordered....\n2   3  Many mystery stories follow the standard whodu...\n3   4  A space ship cruising through the galaxy encou...\n4   5  My favorite film this year. Great characters a...\n5   6  From the beginning of the movie, it gives the ...\n6   7  This is not the worst film I have seen of Pete...\n7   8  Many consider BEAST STABLE to be the last of t...\n8   9  This is a cult film for many reasons. First be...\n9  10  This movie is horrible. Everything in it has b...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Size of train dataset: \",data_train.shape)\nprint(\"Size of test dataset: \",data_test.shape)\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Size of train dataset:  (40000, 2)\nSize of test dataset:  (10000, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sentiment count\ndata_train['sentiment'].value_counts()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"positive    20048\nnegative    19952\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df=data_train,\n                                                                   text_column = 'review',\n                                                                   label_columns = 'sentiment',\n                                                                   val_df = data_test,\n                                                                   \n                                                                   maxlen = 500,\n                                                                   preprocess_mode = 'bert')","execution_count":9,"outputs":[{"output_type":"stream","text":"downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n[██████████████████████████████████████████████████]\nextracting pretrained BERT model...\ndone.\n\ncleanup downloaded zip...\ndone.\n\npreprocessing train...\nlanguage: en\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"done."},"metadata":{}},{"output_type":"stream","text":"Is Multi-Label? False\npreprocessing test...\nlanguage: en\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"done."},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"[array([[  101,  2025,  2069, ...,     0,     0,     0],\n        [  101, 13877,  1024, ...,  2003,  2055,   102],\n        [  101,  2116,  6547, ...,     0,     0,     0],\n        ...,\n        [  101,  2108,  1037, ...,     0,     0,     0],\n        [  101,  7929,  2034, ...,     0,     0,     0],\n        [  101,  7910, 23644, ...,  2143,  1010,   102]]),\n array([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]])]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = text.text_classifier(name = 'bert',\n                             train_data = (X_train, y_train),\n                             preproc = preproc)","execution_count":11,"outputs":[{"output_type":"stream","text":"Is Multi-Label? False\nmaxlen is 500\ndone.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here we have taken batch size as 6 as from the documentation it is recommend to use this with maxlen as 500\n\nlearner = ktrain.get_learner(model=model, train_data=(X_train, y_train),\n                   \n                   batch_size = 6)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.fit_onecycle(lr = 2e-5, epochs = 1)\n\npredictor = ktrain.get_predictor(learner.model, preproc)\npredictor.save('bert')","execution_count":13,"outputs":[{"output_type":"stream","text":"\n\nbegin training using onecycle policy with max lr of 2e-05...\n6667/6667 [==============================] - 5397s 810ms/step - loss: 0.2228 - accuracy: 0.9103\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ['this movie was horrible, the plot was really boring. acting was okay',\n        'the fild is really sucked. there is not plot and acting was bad',\n        'what a beautiful movie. great plot. acting was good. will see it again']","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor.predict(data)","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"['negative', 'negative', 'positive']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dflist=data_test['review'].to_list()\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test['prediction']=predictor.predict(dflist)\npredictor.get_classes()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\npredictor.save('/kaggle/working/bert')\ndata_test.to_excel('/kaggle/working/Prediction.xlsx')\n!zip -r file.zip '/kaggle/working/'\nprint(os.listdir())\nfrom IPython.display import FileLink\nFileLink('file.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test_data.to_excel('Output.xlsx')"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}